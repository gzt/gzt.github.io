<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on gzt does statistics</title>
    <link>http://gzt.github.io/</link>
    <description>Recent content in Home on gzt does statistics</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 12 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://gzt.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>http://gzt.github.io/about/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/about/</guid>
<<<<<<< HEAD
      <description>I&amp;rsquo;m Geoff Thompson, a PhD candidate at the Department of Statistics at Iowa State University. I should be defending this summer (2018). My research interests have been in clustering and other classification problems as well as unsupervised or semisupervised learning. But, generally, a lot of aspects of going from large messy real-world data to the truth of what is going on. I work on the &amp;ldquo;Model&amp;rdquo; part of the &amp;ldquo;Import, Tidy, Transform, Visualize, and Model Data&amp;rdquo; formulation of Data Science.</description>
    </item>
    
    <item>
      <title>I just can&#39;t with this one</title>
      <link>http://gzt.github.io/post/i-just-can-t-with-this-one/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/i-just-can-t-with-this-one/</guid>
      <description>As scientists, we have ethical responsibilities related to the uses of our work, and sometimes these are not entirely obvious. We have to at least pretend to think about them. If our work is “basic” research, we can claim moral ambiguity sometimes (whether such claims are justified is an empirical question). If our work is “applied”, we have little cover.
When I read articles about uncritical applications of “machine learning” to “social issues”, I just can’t handle it.</description>
    </item>
    
    <item>
      <title>CholWishart now on CRAN</title>
      <link>http://gzt.github.io/post/cholwishart-now-on-cran/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/cholwishart-now-on-cran/</guid>
      <description>I decided to break off from matrixdist the portion dedicated to the Wishart-related functions. They are self-contained and don’t really exist on their own elsewhere (there are a few that include them along with a lot of other functionality, some in C++ but a lot in R), so it’s good to have a little package that offers them on their own. Not everybody would want or need matrixdist and it’s good to offer the option without polluting the NAMESPACE.</description>
    </item>
    
    <item>
      <title>Why don&#39;t my results agree with some other function?</title>
      <link>http://gzt.github.io/post/why-don-t-my-results-agree-with-some-other-function/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/why-don-t-my-results-agree-with-some-other-function/</guid>
      <description>Or even with other functions in the same package? With a set seed, one would expect the random draws from two equivalent distributions to be the same.
library(&amp;#39;matrixdist&amp;#39;) set.seed(20180223) rmatrixnorm(n = 1, mean = matrix(0, nrow = 1, ncol = 5), array = T) ## , , 1 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1.153053 -0.08006347 1.040504 0.9671611 -0.002402098 set.seed(20180223) rmatrixnorm(n = 1, mean = matrix(0, nrow = 5, ncol = 1), array = T) ## , , 1 ## ## [,1] ## [1,] 1.</description>
||||||| merged common ancestors
      <description>I&amp;rsquo;m Geoff Thompson, a PhD candidate at the Department of Statistics at Iowa State University. I should be defending this year. My research interests have been in clustering and other classification problems as well as unsupervised or semisupervised learning. But, generally, a lot of aspects of going from large messy real-world data to the truth of what is going on. Some call it data science but I call it statistics.</description>
=======
      <description>I&amp;rsquo;m Geoff Thompson, a PhD candidate at the Department of Statistics at Iowa State University. I should be defending this summer (2018). My research interests have been in clustering and other classification problems as well as unsupervised or semisupervised learning. But, generally, a lot of aspects of going from large messy real-world data to the truth of what is going on. I work on the &amp;ldquo;Model&amp;rdquo; part of the &amp;ldquo;Import, Tidy, Transform, Visualize, and Model Data&amp;rdquo; formulation of Data Science.</description>
    </item>
    
    <item>
      <title>CholWishart now on CRAN</title>
      <link>http://gzt.github.io/post/cholwishart-now-on-cran/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/cholwishart-now-on-cran/</guid>
      <description>I decided to break off from matrixdist the portion dedicated to the Wishart-related functions. They are self-contained and don’t really exist on their own elsewhere (there are a few that include them along with a lot of other functionality, some in C++ but a lot in R), so it’s good to have a little package that offers them on their own. Not everybody would want or need matrixdist and it’s good to offer the option without polluting the NAMESPACE.</description>
    </item>
    
    <item>
      <title>Why don&#39;t my results agree with some other function?</title>
      <link>http://gzt.github.io/post/why-don-t-my-results-agree-with-some-other-function/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/why-don-t-my-results-agree-with-some-other-function/</guid>
      <description>Or even with other functions in the same package? With a set seed, one would expect the random draws from two equivalent distributions to be the same.
library(&amp;#39;matrixdist&amp;#39;) set.seed(20180223) rmatrixnorm(n = 1, mean = matrix(0, nrow = 1, ncol = 5), array = T) ## , , 1 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1.153053 -0.08006347 1.040504 0.9671611 -0.002402098 set.seed(20180223) rmatrixnorm(n = 1, mean = matrix(0, nrow = 5, ncol = 1), array = T) ## , , 1 ## ## [,1] ## [1,] 1.</description>
>>>>>>> 9aaa9ac341ebe55b359b1e22e3baffe9cd0d692f
    </item>
    
    <item>
      <title>Software for Matrix Variate LDA and QDA</title>
      <link>http://gzt.github.io/post/software-for-matrix-variate-lda-and-qda/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/software-for-matrix-variate-lda-and-qda/</guid>
      <description>In the previous post, I had some rough notes on classification of matrix variate data. In the matrixdist package, I now have some functions for training a linear or quadratic classifier. The usage is pretty similar to the function MASS::lda() or MASS::qda(), however it requires the input as an array or list of matrices and the group variable provided as a vector (that is, it cannot handle data frames or the formula interface directly, which is reasonable, as there is no immediately clear way to make that work for a collection of matrices - anybody using it would have to roll their own solutions anyway).</description>
    </item>
    
    <item>
      <title>Notes on Discriminant Analysis for Matrix Variate Distributions</title>
      <link>http://gzt.github.io/post/notes-on-discriminant-analysis-for-matrix-variate-distributions/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/notes-on-discriminant-analysis-for-matrix-variate-distributions/</guid>
      <description>I have some brief notes for a discussion here so I’m posting them even though they’re a little incomplete because why not? Two-class classification for matrix variate normal distributions.
Expected Cost of Misclassification ECM is expected cost of misclassification. Suppose there are two populations, \(\pi_1\) and \(\pi_2\) with prior probabilities of belonging to these classes, \(p_1\) and \(p_2\). Define a function, \(c(1|2)\) as the cost of misclassifying a member of population \(\pi_2\) as a member of class \(1\) (and vice versa).</description>
    </item>
    
    <item>
      <title>Matrixdist News</title>
      <link>http://gzt.github.io/post/matrixdist-new/</link>
      <pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/matrixdist-new/</guid>
      <description>I have just finished setting up handling for AR(1) and compound symmetry variance structures in my maximum likelihood estimation function for matrix variate normal distributions in matrixdist. This means I may submit it to CRAN soon (it’s currently available on github). An example:
library(matrixdist) A &amp;lt;- rmatrixnorm(100, mean=array(0,dim=c(3,4)), U = toeplitz(c(1,.8,.64)), V = rWishart(1,7,diag(4))[,,1]) MLmatrixnorm(A, row.variance=&amp;quot;AR(1)&amp;quot;) $mean [,1] [,2] [,3] [,4] [1,] -0.14927218 0.14837747 -0.12314591 0.2203576 [2,] 0.03791425 0.00645731 -0.05735620 0.</description>
    </item>
    
    <item>
      <title>Working with C and R</title>
      <link>http://gzt.github.io/post/working-with-c-and-r/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/working-with-c-and-r/</guid>
      <description>or: adventures with .Call Generally I work either in R or in C but not both. My research is trying to do some big things faster and there’s existing code in C that I’m working with. I might dump some output and then explore it in R, but I don’t need to interface between them. On the other hand, when consulting with others it’s going to come down to good old-fashioned statistics so that happens in R (or SAS if applicable, for some things it’s better and for some things the people you’re working with are using SAS).</description>
    </item>
    
    <item>
      <title>why I&#39;ve been using base plot</title>
      <link>http://gzt.github.io/post/why-i-ve-been-using-base-plot/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/why-i-ve-been-using-base-plot/</guid>
      <description>Nobody cares what I think, of course. The grammar of graphics is The Way, and ggplot2 is my preferred method of visualization. I never even really tried to make my own graphs with base plot until some point last fall (so: after 5 years of R) - I mean, I’m at Iowa State, after all. I don’t hang out with our Graphics Group as much as I should but that’s how I think about plotting.</description>
    </item>
    
    <item>
      <title>Some linear algebra tricks</title>
      <link>http://gzt.github.io/post/some-linear-algebra-tricks/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/some-linear-algebra-tricks/</guid>
      <description>You may have come across some of this before, but I wanted to write this down for some future reference because it came up in a project of mine and I want to refer to it later. The general theme is that if you know something about the structure of the matrices you’re working with, you can sometimes speed some things up.
Avoiding matrix inversion. Why do you want to invert your matrix?</description>
    </item>
    
  </channel>
</rss>