<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on gzt does statistics</title>
    <link>http://gzt.github.io/</link>
    <description>Recent content in Home on gzt does statistics</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 12 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://gzt.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>http://gzt.github.io/about/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/about/</guid>
      <description>I&amp;rsquo;m Geoff Thompson, a PhD candidate at the Department of Statistics at Iowa State University. I should be defending this summer (2018). My research interests have been in clustering and other classification problems as well as unsupervised or semisupervised learning. But, generally, a lot of aspects of going from large messy real-world data to the truth of what is going on. I work on the &amp;ldquo;Model&amp;rdquo; part of the &amp;ldquo;Import, Tidy, Transform, Visualize, and Model Data&amp;rdquo; formulation of Data Science.</description>
    </item>
    
    <item>
      <title>The R Uncoast Unconference</title>
      <link>http://gzt.github.io/post/the-r-uncoast-unconference/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/the-r-uncoast-unconference/</guid>
      <description>Last week, I participated in the Uncoast Unconference, which was a great opportunity to catch up with some old colleagues, meet a bunch of new people, and collaborate on some interesting projects.
The way these unconferences work, if you’re not familiar (I wasn’t, it was my first), is that people get together and decide on some project to work on (which can, hopefully, be finished in two days). Experience levels range from complete beginners to R Core contributors.</description>
    </item>
    
    <item>
      <title>Know your PRNGs</title>
      <link>http://gzt.github.io/post/know-your-prngs/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/know-your-prngs/</guid>
      <description>TL;DR version: if all you&amp;rsquo;re using the standalone R math library in C for is generating uniform random numbers, I have a little C program to remove that dependency as long as you don&amp;rsquo;t mind your seeds not having the same output as R. I might even fix that later.
I fell into a rabbit hole recently - I do a fair amount of work in C using the R standalone math library for pseudo-random number generation (PRNGs) and sometimes some of its special functions (rather than, say, working in C so it will be called from R or trying to implement a PRNG myself or a special function myself - leave RNGs and numerical analysis to experts).</description>
    </item>
    
    <item>
      <title>A Quick Note about rInvWishart in CholWishart</title>
      <link>http://gzt.github.io/post/a-quick-note-about-rinvwishart-in-cholwishart/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/a-quick-note-about-rinvwishart-in-cholwishart/</guid>
      <description>People wanting to simulate from the inverse Wishart may want their inverses to be the exact inverses of what are generated by rWishart or may be wondering about how, exactly, rInvWishart is parameterized. You might expect that simulating from rWishart with a covariance matrix Sigma gives results related to simulating from rInvWishart with covariance Sigma or you might want it with covariance Sigma^(-1). So which is it?
library(&amp;#39;CholWishart&amp;#39;) A &amp;lt;- 1.</description>
    </item>
    
    <item>
      <title>Quick Checks of Your Simulated Distributions</title>
      <link>http://gzt.github.io/post/verifying-your-simulations/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/verifying-your-simulations/</guid>
      <description>I’ve written a couple packages for simulating from some distributions (Wishart-related distributions in CholWishart and matrix-variate distributions in matrixdist) and sometimes when a new function has been written or has been refactored, you need some ways to verify it is giving the answers you expect. There is an entire literature on this in general, but I am going to discuss one handy trick I sometimes use if there isn’t much theory to rely on or if you just want some quick heuristic to show you are in the right ballpark.</description>
    </item>
    
    <item>
      <title>New Version of CholWishart Released</title>
      <link>http://gzt.github.io/post/new-version-of-cholwishart-released/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/new-version-of-cholwishart-released/</guid>
      <description>I have just released version 0.9.4 of CholWishart. If you want to simulate from the inverse Wishart, compute densities for the Wishart or inverse Wishart, or use the multivariate gamma or digamma function, this is the R package for you. It has a few other functions (notably, its namesake which generates random samples from the Wishart distribution and returns their Cholesky decomposition).
New in this release: the pseudo Wishart and its pseudo-inverse, the generalized inverse Wishart.</description>
    </item>
    
    <item>
      <title>I just can&#39;t with this one</title>
      <link>http://gzt.github.io/post/i-just-can-t-with-this-one/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/i-just-can-t-with-this-one/</guid>
      <description>As scientists, we have ethical responsibilities related to the uses of our work, and sometimes these are not entirely obvious. We have to at least pretend to think about them. If our work is “basic” research, we can claim moral ambiguity sometimes (whether such claims are justified is an empirical question). If our work is “applied”, we have little cover.
When I read articles about uncritical applications of “machine learning” to “social issues”, I just can’t handle it.</description>
    </item>
    
    <item>
      <title>CholWishart now on CRAN</title>
      <link>http://gzt.github.io/post/cholwishart-now-on-cran/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/cholwishart-now-on-cran/</guid>
      <description>I decided to break off from matrixdist the portion dedicated to the Wishart-related functions. They are self-contained and don’t really exist on their own elsewhere (there are a few that include them along with a lot of other functionality, some in C++ but a lot in R), so it’s good to have a little package that offers them on their own. Not everybody would want or need matrixdist and it’s good to offer the option without polluting the NAMESPACE.</description>
    </item>
    
    <item>
      <title>Why don&#39;t my results agree with some other function?</title>
      <link>http://gzt.github.io/post/why-don-t-my-results-agree-with-some-other-function/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/why-don-t-my-results-agree-with-some-other-function/</guid>
      <description>Or even with other functions in the same package? With a set seed, one would expect the random draws from two equivalent distributions to be the same.
library(&amp;#39;matrixdist&amp;#39;) set.seed(20180223) rmatrixnorm(n = 1, mean = matrix(0, nrow = 1, ncol = 5), array = T) ## , , 1 ## ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1.153053 -0.08006347 1.040504 0.9671611 -0.002402098 set.seed(20180223) rmatrixnorm(n = 1, mean = matrix(0, nrow = 5, ncol = 1), array = T) ## , , 1 ## ## [,1] ## [1,] 1.</description>
    </item>
    
    <item>
      <title>Software for Matrix Variate LDA and QDA</title>
      <link>http://gzt.github.io/post/software-for-matrix-variate-lda-and-qda/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/software-for-matrix-variate-lda-and-qda/</guid>
      <description>In the previous post, I had some rough notes on classification of matrix variate data. In the matrixdist package, I now have some functions for training a linear or quadratic classifier. The usage is pretty similar to the function MASS::lda() or MASS::qda(), however it requires the input as an array or list of matrices and the group variable provided as a vector (that is, it cannot handle data frames or the formula interface directly, which is reasonable, as there is no immediately clear way to make that work for a collection of matrices - anybody using it would have to roll their own solutions anyway).</description>
    </item>
    
    <item>
      <title>Notes on Discriminant Analysis for Matrix Variate Distributions</title>
      <link>http://gzt.github.io/post/notes-on-discriminant-analysis-for-matrix-variate-distributions/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/notes-on-discriminant-analysis-for-matrix-variate-distributions/</guid>
      <description>I have some brief notes for a discussion here so I’m posting them even though they’re a little incomplete because why not? Two-class classification for matrix variate normal distributions.
Expected Cost of Misclassification ECM is expected cost of misclassification. Suppose there are two populations, \(\pi_1\) and \(\pi_2\) with prior probabilities of belonging to these classes, \(p_1\) and \(p_2\). Define a function, \(c(1|2)\) as the cost of misclassifying a member of population \(\pi_2\) as a member of class \(1\) (and vice versa).</description>
    </item>
    
    <item>
      <title>Matrixdist News</title>
      <link>http://gzt.github.io/post/matrixdist-new/</link>
      <pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/matrixdist-new/</guid>
      <description>I have just finished setting up handling for AR(1) and compound symmetry variance structures in my maximum likelihood estimation function for matrix variate normal distributions in matrixdist. This means I may submit it to CRAN soon (it’s currently available on github). An example:
library(matrixdist) A &amp;lt;- rmatrixnorm(100, mean=array(0,dim=c(3,4)), U = toeplitz(c(1,.8,.64)), V = rWishart(1,7,diag(4))[,,1]) MLmatrixnorm(A, row.variance=&amp;quot;AR(1)&amp;quot;) $mean [,1] [,2] [,3] [,4] [1,] 0.07425945 -0.1277509 -0.15602140 0.5687155 [2,] 0.09761592 -0.1253225 -0.10766017 0.</description>
    </item>
    
    <item>
      <title>Working with C and R</title>
      <link>http://gzt.github.io/post/working-with-c-and-r/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/working-with-c-and-r/</guid>
      <description>or: adventures with .Call Generally I work either in R or in C but not both. My research is trying to do some big things faster and there’s existing code in C that I’m working with. I might dump some output and then explore it in R, but I don’t need to interface between them. On the other hand, when consulting with others it’s going to come down to good old-fashioned statistics so that happens in R (or SAS if applicable, for some things it’s better and for some things the people you’re working with are using SAS).</description>
    </item>
    
    <item>
      <title>why I&#39;ve been using base plot</title>
      <link>http://gzt.github.io/post/why-i-ve-been-using-base-plot/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/why-i-ve-been-using-base-plot/</guid>
      <description>Nobody cares what I think, of course. The grammar of graphics is The Way, and ggplot2 is my preferred method of visualization. I never even really tried to make my own graphs with base plot until some point last fall (so: after 5 years of R) - I mean, I’m at Iowa State, after all. I don’t hang out with our Graphics Group as much as I should but that’s how I think about plotting.</description>
    </item>
    
    <item>
      <title>Some linear algebra tricks</title>
      <link>http://gzt.github.io/post/some-linear-algebra-tricks/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/some-linear-algebra-tricks/</guid>
      <description>You may have come across some of this before, but I wanted to write this down for some future reference because it came up in a project of mine and I want to refer to it later. The general theme is that if you know something about the structure of the matrices you’re working with, you can sometimes speed some things up.
Avoiding matrix inversion. Why do you want to invert your matrix?</description>
    </item>
    
  </channel>
</rss>