<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linear algebra on gzt does statistics</title>
    <link>http://gzt.github.io/tags/linear-algebra/</link>
    <description>Recent content in Linear algebra on gzt does statistics</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 08 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://gzt.github.io/tags/linear-algebra/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>New Version of CholWishart Released</title>
      <link>http://gzt.github.io/post/new-version-of-cholwishart-released/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/new-version-of-cholwishart-released/</guid>
      <description>I have just released version 0.9.4 of CholWishart. If you want to simulate from the inverse Wishart, compute densities for the Wishart or inverse Wishart, or use the multivariate gamma or digamma function, this is the R package for you. It has a few other functions (notably, its namesake which generates random samples from the Wishart distribution and returns their Cholesky decomposition).
New in this release: the pseudo Wishart and its pseudo-inverse, the generalized inverse Wishart.</description>
    </item>
    
    <item>
      <title>CholWishart now on CRAN</title>
      <link>http://gzt.github.io/post/cholwishart-now-on-cran/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/cholwishart-now-on-cran/</guid>
      <description>I decided to break off from matrixdist the portion dedicated to the Wishart-related functions. They are self-contained and don’t really exist on their own elsewhere (there are a few that include them along with a lot of other functionality, some in C++ but a lot in R), so it’s good to have a little package that offers them on their own. Not everybody would want or need matrixdist and it’s good to offer the option without polluting the NAMESPACE.</description>
    </item>
    
    <item>
      <title>Notes on Discriminant Analysis for Matrix Variate Distributions</title>
      <link>http://gzt.github.io/post/notes-on-discriminant-analysis-for-matrix-variate-distributions/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/notes-on-discriminant-analysis-for-matrix-variate-distributions/</guid>
      <description>I have some brief notes for a discussion here so I’m posting them even though they’re a little incomplete because why not? Two-class classification for matrix variate normal distributions.
Expected Cost of Misclassification ECM is expected cost of misclassification. Suppose there are two populations, \(\pi_1\) and \(\pi_2\) with prior probabilities of belonging to these classes, \(p_1\) and \(p_2\). Define a function, \(c(1|2)\) as the cost of misclassifying a member of population \(\pi_2\) as a member of class \(1\) (and vice versa).</description>
    </item>
    
    <item>
      <title>Some linear algebra tricks</title>
      <link>http://gzt.github.io/post/some-linear-algebra-tricks/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>http://gzt.github.io/post/some-linear-algebra-tricks/</guid>
      <description>You may have come across some of this before, but I wanted to write this down for some future reference because it came up in a project of mine and I want to refer to it later. The general theme is that if you know something about the structure of the matrices you’re working with, you can sometimes speed some things up.
Avoiding matrix inversion. Why do you want to invert your matrix?</description>
    </item>
    
  </channel>
</rss>